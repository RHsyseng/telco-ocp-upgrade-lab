<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Untitled :: LAB - Telco OCP Upgrade Lab</title>
    <link rel="canonical" href="https://labs.sysdeseng.com/4.10/lcm_upgrades.html">
    <meta name="generator" content="Antora 3.1.6">
    <link rel="stylesheet" href="../_/css/site.css">
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com/en/solutions/telecommunications" target="_blank"><img src="../_/img/Logo-Red_Hat-A-Reverse-RGB.png" height="40px" alt="Red Hat Telco Solutions"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="https://labs.sysdeseng.com">LAB - Telco OCP Upgrade Lab</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://developers.redhat.com/ebooks/" target="_blank">Books</a>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">More Tutorials</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://redhat-developer-demos.github.io/kubernetes-tutorial/" target="_blank">Kubernetes</a>
            <a class="navbar-item" href="https://redhat-developer-demos.github.io/istio-tutorial/" target="_blank">Istio</a>
            <a class="navbar-item" href="https://redhat-developer-demos.github.io/quarkus-tutorial/" target="_blank">Quarkus</a>
            <a class="navbar-item" href="https://redhat-developer-demos.github.io/knative-tutorial/" target="_blank">Knative</a>
            <a class="navbar-item" href="https://redhat-developer-demos.github.io/tekton-tutorial/" target="_blank">Tekton</a>
          </div>
        </div>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="4.10" data-version="">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="index.html"></a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">Welcome</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="index.html#contributors">Contributors</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="introduction.html">Introduction</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="introduction.html#lab-aim">Who is this lab aimed at?</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="introduction.html#lab-software-versions">Lab Software Versions</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="API-Compatibility.html">OCP API Compatibility Policy</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="API-Compatibility.html#cnf-api-compatibility">CNF API Compatibility</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="API-Compatibility.html#k8s-skew">Kubernetes Version Skew</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="API-Compatibility.html#ocp-upgrade-path">OpenShift Upgrade Path</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
<nav class="breadcrumbs" aria-label="breadcrumbs">
</nav>
  <div class="edit-this-page"><a href="file:///Users/rfisher/github/telco-ocp-upgrade-lab/documentation/modules/ROOT/pages/lcm_upgrades.adoc">Edit this Page</a></div>
</div>
  <div class="content">
<article class="doc">
<div id="toc" class="toc">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_lifecycle_management">1. LifeCycle Management</a>
<ul class="sectlevel2">
<li><a href="#_scope">1.1. Scope</a></li>
<li><a href="#_ocp_api_compatibility_policy">1.2. OCP API Compatibility Policy</a></li>
<li><a href="#_cnf_upgrade_preparation">1.3. CNF Upgrade Preparation</a>
<ul class="sectlevel3">
<li><a href="#_cnf_requirements_document">1.3.1. CNF Requirements Document</a></li>
<li><a href="#_pod_disruption_budget">1.3.2. POD Disruption Budget</a></li>
<li><a href="#_pod_anti_affinity">1.3.3. POD Anti-affinity</a></li>
<li><a href="#_liveness_readiness_probes">1.3.4. Liveness / Readiness Probes</a></li>
</ul>
</li>
<li><a href="#_ocp_upgrade_preparation">1.4. OCP Upgrade Preparation</a>
<ul class="sectlevel3">
<li><a href="#_firmware_compatibility">1.4.1. Firmware compatibility</a></li>
<li><a href="#_layer_product_compatibility">1.4.2. Layer product compatibility</a></li>
<li><a href="#_prepare_mcps">1.4.3. Prepare MCPs</a></li>
<li><a href="#_environment_considerations">1.4.4. Environment considerations</a></li>
<li><a href="#_platform_preparation">1.4.5. Platform preparation</a></li>
</ul>
</li>
<li><a href="#_upgrade_process_flow">1.5. Upgrade Process Flow</a>
<ul class="sectlevel3">
<li><a href="#_overview">1.5.1. Overview</a></li>
<li><a href="#_z_stream">1.5.2. Z-Stream</a></li>
<li><a href="#_eus_to_eus">1.5.3. EUS to EUS</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="sect1">
<h2 id="_lifecycle_management"><a class="anchor" href="#_lifecycle_management"></a>1. LifeCycle Management</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_scope"><a class="anchor" href="#_scope"></a>1.1. Scope</h3>
<div class="paragraph">
<p>This document is intended to discuss OpenShift LifeCycle management for Telecommunication Network Function Core
clusters. The specific size of the cluster has a few differences which are called out specifically at times in this
document but this is meant to cover most clusters from 10 nodes to the largest cluster certified by the telco scale
team. This includes some scenarios for mixed workload clusters.</p>
</div>
<div class="paragraph">
<p>This document will discuss the following upgrade scenarios:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Z-Stream</p>
</li>
<li>
<p>Y-Stream</p>
</li>
<li>
<p>EUS to EUS</p>
</li>
<li>
<p>Y+3 (i.e.: 4.9 to 4.12)
Each of these has different considerations which are called out specifically as needed, in this document. <br>
There is also a dedicated section which will review what is called a Blue/Green migration upgrade. This solution is
useful in situations where the recommended in-service upgrade for Y+3 is not enough for a cluster or the upgrade will
encompass more than Y+3.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_ocp_api_compatibility_policy"><a class="anchor" href="#_ocp_api_compatibility_policy"></a>1.2. OCP API Compatibility Policy</h3>
<div class="paragraph">
<p>The most important thing to understand when considering which Z-release to upgrade to inside of a new Y-release is what
patches need to be in the new Z-release. In other words if you are currently at OCP 4.11.28 you will need to make sure
to upgrade to a Z-release of 4.12 that has all of the patches in it that were applied to 4.11.28, otherwise you will
break the built-in compatibility of Kubernetes.<br>
This is called the Kubernetes version skew policy and can be found at: <a href="https://kubernetes.io/releases/version-skew-policy">https://kubernetes.io/releases/version-skew-policy</a> <br>
This can also be seen in the following graphic:</p>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/k8s-vers-skew.png" alt="k8s vers skew">
</div>
<div class="title">Figure 1. K8s Version Skey</div>
</div>
<div class="paragraph">
<p>Please also note that not all releases of OCP can be upgraded to any arbitrary Z-release even if they contain all of
the required patches. You can use the upgrade graph tool (<a href="https://access.redhat.com/labs/ocpupgradegraph/update_path">https://access.redhat.com/labs/ocpupgradegraph/update_path</a>)
to determine if the path is valid for your z-release. You should also always verify with your Sales Engineer or
Technical Account Manager at Red Hat to make sure the upgrade path is valid for Telco implementations.</p>
</div>
</div>
<div class="sect2">
<h3 id="_cnf_upgrade_preparation"><a class="anchor" href="#_cnf_upgrade_preparation"></a>1.3. CNF Upgrade Preparation</h3>
<div class="paragraph">
<p>The life of a POD is an important topic to understand. This section will describe several topics that are important to
keeping your CNF PODs healthy and allow the cluster to properly schedule them during an upgrade.</p>
</div>
<div class="sect3">
<h4 id="_cnf_requirements_document"><a class="anchor" href="#_cnf_requirements_document"></a>1.3.1. CNF Requirements Document</h4>
<div class="paragraph">
<p>Before you go any further, please read through the <a href="https://connect.redhat.com/sites/default/files/2022-05/Cloud%20Native%20Network%20Function%20Requirements%201-3.pdf">CNF requirements document</a>.
In this section a few of the most important points will be discussed but the CNF Requirements Document has additional
detail and other important topics.</p>
</div>
</div>
<div class="sect3">
<h4 id="_pod_disruption_budget"><a class="anchor" href="#_pod_disruption_budget"></a>1.3.2. POD Disruption Budget</h4>
<div class="paragraph">
<p>Each set of PODs in a deployment can be given a specific minimum number of PODs that should be running in order to keep
from disrupting the functionality of the CNF, thus called the POD disruption budget (PDB). However, this budget can be
improperly configured. <br>
For example, if you have 4 PODs in a deployment and your PDB is set to 4, this means that you are telling the scheduler
that you NEED 4 PODs running at all times. Therefore, in this scenario ZERO PODs can come down.</p>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/PDB-full.jpg" alt="PDB full">
</div>
<div class="title">Figure 2. Deployment with no PDB</div>
</div>
<div class="paragraph">
<p>To fix this, the PDB can be set to 2, letting 2 of the 4 pods to be scheduled as down and this would then let the worker
nodes where those PODs are located be rebooted.</p>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/PDB-down-2.jpg" alt="PDB down 2">
</div>
<div class="title">Figure 3. Deployment with PDB</div>
</div>
</div>
<div class="sect3">
<h4 id="_pod_anti_affinity"><a class="anchor" href="#_pod_anti_affinity"></a>1.3.3. POD Anti-affinity</h4>
<div class="paragraph">
<p>True high availability requires a duplication of a process to be running on separate hardware, thus making sure that an
application will continue to run if one piece of hardware goes down. OpenShift can easily make that happen since
processes are automatically duplicated in separate PODs within a deployment. However, those PODs need to have
anti-affinity set on them so that they are NOT running on the same hardware. It so happens that anti-affinity also
helps during upgrades because it makes sure that PODs are on different worker nodes, therefore allowing enough PODs to
come down even after considering their PDB.</p>
</div>
</div>
<div class="sect3">
<h4 id="_liveness_readiness_probes"><a class="anchor" href="#_liveness_readiness_probes"></a>1.3.4. Liveness / Readiness Probes</h4>
<div class="paragraph">
<p>OpenShift and Kubernetes have some built in features that not everyone takes advantage of called
<a href="https://docs.openshift.com/container-platform/4.12/applications/application-health.html">liveness and readiness probes</a>.
These are very important when POD deployments are dependent upon keeping state for their application. This document
won’t go into detail regarding these probes but please review the <a href="https://docs.openshift.com/container-platform/4.12/applications/application-health.html">OpenShift documentation</a>
on how to implement their use.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_ocp_upgrade_preparation"><a class="anchor" href="#_ocp_upgrade_preparation"></a>1.4. OCP Upgrade Preparation</h3>
<div class="sect3">
<h4 id="_firmware_compatibility"><a class="anchor" href="#_firmware_compatibility"></a>1.4.1. Firmware compatibility</h4>
<div class="paragraph">
<p>All hardware vendors will advise that it is always best to be on their latest certified version of firmware for their
hardware. In the telco world this comes with a trust but verify approach due to the high throughput nature of telco
CNFs. Therefore, it is important to have a regimented group who can test the current and latest firmware from any vendor
to make sure that all components will work with both. It is not always recommended to upgrade firmware in conjunction
with an OCP upgrade however if it is possible to test the latest release of firmware that will improve the odds that
you won’t run into issues down the road.<br>
Upgrading firmware is a very important debate because the process can be very intrusive and has a potential for causing
a node to require manual interventions before the node will come back online. On the other hand it may be imperative to
upgrade the firmware due to security fixes, new required functionality or compatibility with the new release of OCP
components. Therefore, it is up to everyone to verify with their hardware vendors, verify compatibility with OCP
components and perform tests in their lab before moving forward.</p>
</div>
</div>
<div class="sect3">
<h4 id="_layer_product_compatibility"><a class="anchor" href="#_layer_product_compatibility"></a>1.4.2. Layer product compatibility</h4>
<div class="paragraph">
<p>It is important to make sure all layered products will run on the new version of OCP that you will be moving to. This,
very much, includes all Operators.</p>
</div>
<div class="paragraph">
<p>Verify the current installed list of Operators installed on your cluster. For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre># oc get csv -A
NAMESPACE                              NAME                                 DISPLAY          VERSION   REPLACES                             PHASE
chapter2                               gitlab-operator-kubernetes.v0.17.2   GitLab           0.17.2    gitlab-operator-kubernetes.v0.17.1   Succeeded
openshift-operator-lifecycle-manager   packageserver                        Package Server   0.19.0                                         Succeeded</pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_prepare_mcps"><a class="anchor" href="#_prepare_mcps"></a>1.4.3. Prepare MCPs</h4>
<div class="paragraph">
<p>Prepare your Machine Config Pool (MCP) labels by grouping your nodes, depending on the number of nodes in your cluster.
MCPs should be split up into 8 to 10 nodes per group. However, there is no hard fast rule as to how many nodes need to
be in each MCP. The purpose of these MCPs is to group nodes together so that a group of nodes can be controlled
independently of the rest. Additional information and examples can be found <a href="https://docs.openshift.com/container-platform/4.12/updating/update-using-custom-machine-config-pools.html">here, under the canary rollout documentation</a>.<br>
These MCPs will be used to un-pause a set of nodes during the upgrade process, thus allowing them to be upgraded and
rebooted at a determined time instead of at the pleasure of the scheduler. Please review the upgrade process flow
section, below, for more details on the pause/un-pause process.</p>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/5Rack-MCP.jpg" alt="5Rack MCP">
</div>
<div class="title">Figure 4. Worker node MCPs in a 5 rack cluster</div>
</div>
<div class="paragraph">
<p>The division and size of these MCPs can vary depending on many factors. In general the standard division is between 8
and 10 nodes per MCP to allow the operations team to control how many nodes are taken down at a time.</p>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/LBorHT-MCP.jpg" alt="LBorHT MCP">
</div>
<div class="title">Figure 5. Separate MCPs inside of a group of Load Balancer or purpose built nodes</div>
</div>
<div class="paragraph">
<p>In larger clusters there is quite often a need to separate out several nodes for purposes like Load Balancing or other
high throughput purposes, which usually have different machine sets to configure SR-IOV. In these cases we do not want
to upgrade all of these nodes without getting a chance to test during the upgrade. Therefore, we need to separate them
out into at least 3 different MCPs and unpause them individually.</p>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/Worker-MCP.jpg" alt="Worker MCP">
</div>
<div class="title">Figure 6. Small cluster worker MCPs</div>
</div>
<div class="paragraph">
<p>Smaller cluster example with 1 rack</p>
</div>
<div class="paragraph">
<p>The process and pace at which you un-pause the MCPs is determined by your CNFs and their configuration. Please review
the sections on PDB and anti-affinity for CNFs. If your CNF can properly handle scheduling within an OpenShift cluster
you can un-pause several MCPs at a time and set the MaxUnavailable to as high as 50%. This will allow as many as half
of the nodes in your MCPs to restart and upgrade. This will reduce the amount of time that is needed for a specific
maintenance window and allow your cluster to upgrade quickly. Hopefully you can see how keeping your PDB and
anti-affinity correctly configured will help in the long run.</p>
</div>
<div class="sect4">
<h5 id="_applying_mcps"><a class="anchor" href="#_applying_mcps"></a>1.4.3.1. Applying MCPs</h5>
<div class="paragraph">
<p>First you can run “oc get mcp” to show your current list of MCPs:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"># oc get mcp</th>
</tr>
</thead>
</table>
<div class="paragraph">
<p>List out all of your nodes:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"># oc get no</th>
</tr>
</thead>
</table>
<div class="paragraph">
<p>Determine, from the above suggestions, how you would like to separate out your worker nodes into machine config pools
(MCP).<br>
In this example we will just use 1 node in each MCP.<br>
We first need to label the nodes so that they can be put into MCPs. We will do this with the following commands:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">oc label node euschannel-worker-0.test.corp node-role.kubernetes.io/<strong>mcp-1</strong>=</th>
</tr>
</thead>
</table>
<div class="paragraph">
<p>This will show up when you run the “oc get node” command:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"># oc get no</th>
</tr>
</thead>
</table>
<div class="paragraph">
<p>Now you need to create yaml files that will apply the labels as MCPs. Here is one example:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">apiVersion: machineconfiguration.openshift.io/v1</th>
</tr>
</thead>
</table>
<div class="paragraph">
<p>For each of these, just run “oc apply -f {filename.yaml}”:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"># oc apply -f test-mcp-2.yaml</th>
</tr>
</thead>
</table>
<div class="paragraph">
<p>Now you can run “oc get mcp” again and your new MCPs will show. Please note that you will still see the original worker
and master MCPs that are part of the cluster.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 100%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top"># oc get mcp</th>
</tr>
</thead>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_environment_considerations"><a class="anchor" href="#_environment_considerations"></a>1.4.4. Environment considerations</h4>
<div class="paragraph">
<p>In Telecommunications environments most of the clusters are kept in an “air gapped” network. Therefore, you will need to
start by updating your offline image repository. When choosing which images to include, please review the OCP API
Compatibility Policy section to make sure the cluster will be able to upgrade to the new version of OCP.</p>
</div>
</div>
<div class="sect3">
<h4 id="_platform_preparation"><a class="anchor" href="#_platform_preparation"></a>1.4.5. Platform preparation</h4>
<div class="paragraph">
<p>This section should be used as a basic set of checks and verifications to make sure that your cluster is ready for an
upgrade. You will more than likely need to add to this list depending on your environment and deployment.</p>
</div>
<div class="sect4">
<h5 id="_basic_cluster_checks"><a class="anchor" href="#_basic_cluster_checks"></a>1.4.5.1. Basic cluster checks</h5>
<div class="paragraph">
<p>First you will need to verify that there are no issues within the cluster that will stop the upgrade. A very easy first
check is to run:</p>
</div>
<div class="listingblock">
<div class="content">
<pre># oc get pod -A | egrep -vi ‘complete|running’

Nothing should be returned from this command</pre>
</div>
</div>
<div class="paragraph">
<p>Next verify that all nodes within the cluster are available:</p>
</div>
<div class="listingblock">
<div class="content">
<pre># oc get node
NAME                           STATUS   ROLES         AGE   VERSION
master-0.fish.corp   Ready    master        92d   v1.24.6+deccab3
master-1.fish.corp   Ready    master        92d   v1.24.6+deccab3
master-2.fish.corp   Ready    master        92d   v1.24.6+deccab3
worker-0.fish.corp   Ready    worker,mcp-1  92d   v1.24.6+deccab3
worker-1.fish.corp   Ready    worker,mcp-2  92d   v1.24.6+deccab3</pre>
</div>
</div>
<div class="paragraph">
<p>Now verify that all cluster operators are ready:</p>
</div>
<div class="listingblock">
<div class="content">
<pre># oc get co
NAME                                       VERSION   AVAILABLE   PROGRESSING   DEGRADED   SINCE   MESSAGE
authentication                             4.11.28   True        False         False      6d8h
baremetal                                  4.11.28   True        False         False      92d
cloud-controller-manager                   4.11.28   True        False         False      92d
cloud-credential                           4.11.28   True        False         False      92d
cluster-autoscaler                         4.11.28   True        False         False      92d
config-operator                            4.11.28   True        False         False      92d
console                                    4.11.28   True        False         False      8d
csi-snapshot-controller                    4.11.28   True        False         False      92d
dns                                        4.11.28   True        False         False      92d
etcd                                       4.11.28   True        False         False      92d
image-registry                             4.11.28   True        False         False      8d
ingress                                    4.11.28   True        False         False      61m
insights                                   4.11.28   True        False         False      92d
kube-apiserver                             4.11.28   True        False         False      92d
kube-controller-manager                    4.11.28   True        False         False      92d
kube-scheduler                             4.11.28   True        False         False      92d
kube-storage-version-migrator              4.11.28   True        False         False      8d
machine-api                                4.11.28   True        False         False      92d
machine-approver                           4.11.28   True        False         False      92d
machine-config                             4.11.28   True        False         False      8d
marketplace                                4.11.28   True        False         False      92d
monitoring                                 4.11.28   True        False         False      85d
network                                    4.11.28   True        False         False      92d
node-tuning                                4.11.28   True        False         False      8d
openshift-apiserver                        4.11.28   True        False         False      92d
openshift-controller-manager               4.11.28   True        False         False      3d23h
openshift-samples                          4.11.28   True        False         False      8d
operator-lifecycle-manager                 4.11.28   True        False         False      92d
operator-lifecycle-manager-catalog         4.11.28   True        False         False      92d
operator-lifecycle-manager-packageserver   4.11.28   True        False         False      92d
service-ca                                 4.11.28   True        False         False      92d
storage                                    4.11.28   True        False         False      92d</pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_upgrade_process_flow"><a class="anchor" href="#_upgrade_process_flow"></a>1.5. Upgrade Process Flow</h3>
<div class="sect3">
<h4 id="_overview"><a class="anchor" href="#_overview"></a>1.5.1. Overview</h4>
<div class="paragraph">
<p>In an effort to specifically sound like a broken record, the preparation phase of the upgrade process is probably the
most important! If everything to this point in the documentation has been followed then barring any unforeseen issues,
like hardware, the rest of this document should all just be step by step.</p>
</div>
<div class="sect4">
<h5 id="_step_1_determine_your_target_release"><a class="anchor" href="#_step_1_determine_your_target_release"></a>1.5.1.1. Step 1: Determine your target release</h5>
<div class="paragraph">
<p>Utilize the <a href="https://access.redhat.com/labs/ocpupgradegraph/update_path">Red Hat update path tool</a> and/or the
<a href="https://github.com/openshift/cincinnati-graph-data/tree/master/channels">cincinnati graph repository</a> to determine which release you will be moving to.</p>
</div>
</div>
<div class="sect4">
<h5 id="_step_2_change_your_channel_if_needed"><a class="anchor" href="#_step_2_change_your_channel_if_needed"></a>1.5.1.2. Step 2: Change your channel (if needed)</h5>
<div class="paragraph">
<p>For a review of all channels you can refer to the <a href="https://docs.openshift.com/container-platform/4.12/updating/understanding-upgrade-channels-release.html">channel release documentation</a>.<br>
Determine what channel you are currently pointed to:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>[root@m640-blade1 ~]# oc get clusterversion -o=jsonpath='{.items[*].spec}' | jq
{
  "channel": "eus-4.10",
  "clusterID": "81ffff37-1234-4b78-1234-1c12347687c6"
}</pre>
</div>
</div>
<div class="paragraph">
<p>Change your channel to point to the new channel:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>[root@m640-blade1 ~]# oc adm upgrade channel eus-4.12
[root@m640-blade1 ~]# oc get clusterversion -o=jsonpath='{.items[*].spec}' | jq
{
  "channel": "eus-4.12",
  "clusterID": "81ffff37-1234-4b78-1234-1c12347687c6"
}</pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
This is moving from EUS to EUS. It would be similar if you were going Y-stream to Y-stream, it would just be
stable-4.10 moving to stable-4.11. However, if it was a change in Z-stream you do not need to change the channel,
because the Z-release will be within that same Y-stream channel.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="_step_3_pause_your_worker_node_mcps"><a class="anchor" href="#_step_3_pause_your_worker_node_mcps"></a>1.5.1.3. Step 3: Pause your worker node MCPs</h5>
<div class="paragraph">
<p>Here is a very simple example that can be used on a small cluster with only one worker node MCP:</p>
</div>
<div class="listingblock">
<div class="content">
<pre>[root@m640-blade1 ~]# oc patch mcp/worker --type merge --patch '{"spec":{"paused":true}}'

[root@m640-blade1 ~]# oc describe mcp | egrep 'Name:|Paused' | egrep -v 'rendered|[0-9][0-9]-'
Name:         master
  Paused:                              false
Name:         mcp-1
  Paused:                             true
Name:         mcp-2
  Paused:                             true
Name:         worker
  Paused:                              false</pre>
</div>
</div>
<div class="paragraph">
<p>For larger clusters with multiple MCPs, please refer to the <a href="https://docs.openshift.com/container-platform/4.12/updating/update-using-custom-machine-config-pools.html">canary rollout documentation</a>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_step_4_double_check_your_cluster_health"><a class="anchor" href="#_step_4_double_check_your_cluster_health"></a>1.5.1.4. Step 4: Double check your cluster health</h5>
<div class="paragraph">
<p>Some suggested checks at this time are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Cluster operators</p>
</li>
<li>
<p>Node status</p>
</li>
<li>
<p>Look for failed pods</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre>[root@m640-blade1 ~]# oc get co
NAME                                       VERSION   AVAILABLE   PROGRESSING   DEGRADED   SINCE   MESSAGE
authentication                             4.11.28   True        False         False      10d
baremetal                                  4.11.28   True        False         False      117d
cloud-controller-manager                   4.11.28   True        False         False      117d
cloud-credential                           4.11.28   True        False         False      118d
cluster-autoscaler                         4.11.28   True        False         False      117d
config-operator                            4.11.28   True        False         False      117d
console                                    4.11.28   True        False         False      3d22h
csi-snapshot-controller                    4.11.28   True        False         False      17d
dns                                        4.11.28   True        False         False      117d
etcd                                       4.11.28   True        False         False      117d
image-registry                             4.11.28   True        False         False      17d
ingress                                    4.11.28   True        False         False      17d
insights                                   4.11.28   True        False         False      117d
kube-apiserver                             4.11.28   True        False         False      117d
kube-controller-manager                    4.11.28   True        False         False      117d
kube-scheduler                             4.11.28   True        False         False      117d
kube-storage-version-migrator              4.11.28   True        False         False      17d
machine-api                                4.11.28   True        False         False      117d
machine-approver                           4.11.28   True        False         False      117d
machine-config                             4.11.28   True        False         False      17d
marketplace                                4.11.28   True        False         False      117d
monitoring                                 4.11.28   True        False         False      17d
network                                    4.11.28   True        False         False      117d
node-tuning                                4.11.28   True        False         False      33d
openshift-apiserver                        4.11.28   True        False         False      117d
openshift-controller-manager               4.11.28   True        False         False      28d
openshift-samples                          4.11.28   True        False         False      33d
operator-lifecycle-manager                 4.11.28   True        False         False      117d
operator-lifecycle-manager-catalog         4.11.28   True        False         False      117d
operator-lifecycle-manager-packageserver   4.11.28   True        False         False      17d
service-ca                                 4.11.28   True        False         False      117d
storage                                    4.11.28   True        False         False      117d

[root@m640-blade1 ~]# oc get no
NAME                           STATUS   ROLES         AGE    VERSION
rftest1-master-0.test.corp   Ready    master        118d   v1.24.6+deccab3
rftest1-master-1.test.corp   Ready    master        118d   v1.24.6+deccab3
rftest1-master-2.test.corp   Ready    master        118d   v1.24.6+deccab3
rftest1-worker-0.test.corp   Ready    mcp,worker    117d   v1.24.6+deccab3
rftest1-worker-1.test.corp   Ready    mcp1,worker   117d   v1.24.6+deccab3

[root@m640-blade1 ~]# oc get po -A | egrep -iv 'running|complete'
(Note: this should return NOTHING)</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_step_5_begin_the_cluster_upgrade"><a class="anchor" href="#_step_5_begin_the_cluster_upgrade"></a>1.5.1.5. Step 5: Begin the cluster upgrade</h5>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 100%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">[root@m640-blade1 ~]# oc adm upgrade --to-latest</p>
<p class="tableblock">Requesting update to 4.9.57</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect4">
<h5 id="_step_6_monitor_the_upgrade"><a class="anchor" href="#_step_6_monitor_the_upgrade"></a>1.5.1.6. Step 6: Monitor the upgrade</h5>
<div class="listingblock">
<div class="content">
<pre>[root@m640-blade1 ~]# watch "oc get clusterversion; echo; oc get co | head -1; oc get co | grep 4.9.57; oc get co | grep 4.8.55; echo; oc get no; echo; oc get po -A | egrep -iv 'running|complete'"


NAME	  VERSION   AVAILABLE   PROGRESSING   SINCE   STATUS
version   4.8.55    True        True          31m     Working towards 4.9.57: 206 of 738 done (27% complete), waiting on openshift-apiserver

NAME                                       VERSION   AVAILABLE   PROGRESSING   DEGRADED   SINCE   MESSAGE
cloud-controller-manager                   4.9.57    True        False         False	  5m32s
config-operator                            4.9.57    True        False         False	  68m
etcd                                       4.9.57    True        False         False	  67m
kube-apiserver                             4.9.57    True        False         False	  63m
kube-controller-manager                    4.9.57    True        False         False	  67m
kube-scheduler                             4.9.57    True        False         False	  66m
machine-api                                4.9.57    True        False         False	  68m
openshift-apiserver                        4.9.57    True        False         False	  64m
authentication                             4.8.55    True        False         False	  49m
baremetal                                  4.8.55    True        False         False	  68m
cloud-credential                           4.8.55    True        False         False	  70m
cluster-autoscaler                         4.8.55    True        False         False	  67m
console                                    4.8.55    True        False         False	  53m
csi-snapshot-controller                    4.8.55    True        False         False	  53m
dns                                        4.8.55    True        False         False	  67m
image-registry                             4.8.55    True        False         False	  14m
ingress                                    4.8.55    True        False         False	  61m
insights                                   4.8.55    True        False         False	  62m
kube-storage-version-migrator              4.8.55    True        False         False	  14m
machine-approver                           4.8.55    True        False         False	  68m
machine-config                             4.8.55    True        False         False	  67m
marketplace                                4.8.55    True        False         False	  67m
monitoring                                 4.8.55    True        False         False	  60m
network                                    4.8.55    True        False         False	  69m
node-tuning                                4.8.55    True        False         False	  67m
openshift-controller-manager               4.8.55    True        False         False	  67m
openshift-samples                          4.8.55    True        False         False	  64m
operator-lifecycle-manager                 4.8.55    True        False         False	  68m
operator-lifecycle-manager-catalog         4.8.55    True        False         False	  68m
operator-lifecycle-manager-packageserver   4.8.55    True        False         False	  53m
service-ca                                 4.8.55    True        False         False	  68m
storage                                    4.8.55    True        False         False	  68m

NAME                              STATUS   ROLES    AGE   VERSION
euschannel-master-0.test.corp   Ready    master   70m   v1.21.14+a17bdb3
euschannel-master-1.test.corp   Ready    master   70m   v1.21.14+a17bdb3
euschannel-master-2.test.corp   Ready    master   70m   v1.21.14+a17bdb3
euschannel-worker-0.test.corp   Ready    worker   62m   v1.21.14+a17bdb3
euschannel-worker-1.test.corp   Ready    worker   62m   v1.21.14+a17bdb3

NAMESPACE                                          NAME                                                         READY   STATUS      RESTARTS      AGE</pre>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_step_6b_eus_to_eus"><a class="anchor" href="#_step_6b_eus_to_eus"></a>1.5.1.7. Step 6b: EUS to EUS</h5>
<div class="paragraph">
<p>When upgrading from EUS to EUS release, refer to the section below for details.</p>
</div>
</div>
<div class="sect4">
<h5 id="_step_7_un_pause_the_worker_mcps"><a class="anchor" href="#_step_7_un_pause_the_worker_mcps"></a>1.5.1.8. Step 7: Un-Pause the worker MCP(s)</h5>
<div class="paragraph">
<p>Once the Control Plane PODs and nodes have completed their upgrade then you can begin the work on the worker node
upgrades.<br>
Refer to the section above discussing recommendations for when to un-pause specific MCPs</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_z_stream"><a class="anchor" href="#_z_stream"></a>1.5.2. Z-Stream</h4>
<div class="paragraph">
<p>The Z-stream updates to a cluster should become business as usual at some point with as minimal of an impact as
possible. There are many reasons for needing a Z-stream update usually coming in the form of security updates and bug
fixes.
Fortunately, during a Z-stream update there is minimal change to the control plane and therefore there is less of an
impact to the cluster.
Unfortunately, there is still a high likelihood that all nodes within the cluster will need to be rebooted.
Z-stream updates are a good time to focus on adding in firmware updates as they have less cluster impact. Firmware
updates also might be required shortly after Y-stream or EUS updates as hardware vendors may have released bug fixes for
problems that were found with new releases of RHCOS. There might also be new functionality that is released in some NIC
firmware as new releases of RHCOS come out. Please work closely with your hardware vendors to keep up to date with your
firmware when possible.</p>
</div>
</div>
<div class="sect3">
<h4 id="_eus_to_eus"><a class="anchor" href="#_eus_to_eus"></a>1.5.3. EUS to EUS</h4>
<div class="paragraph">
<p>EUS (Extended update support) is an even numbered <a href="https://access.redhat.com/support/policy/updates/openshift">release of OpenShift </a>
that will have extended support for up to 24 months. This will allow Red Hat customers and partners to stay on a
specific release much longer than the standard 4 months between OpenShift or Kubernetes releases or the 18 months of
maintenance support. This will reduce the number of upgrades that most Telcos will need to perform as they will be able
to jump 2 minor releases with each upgrade.</p>
</div>
<div class="paragraph">
<p>In an upgrade like this each application will need to verify against the <a href="https://kubernetes.io/docs/reference/using-api/deprecation-guide/">API deprecated list</a>
to make sure all your CNFs will still function once you upgrade to the new version of OCP.</p>
</div>
<div class="paragraph">
<p>This jump in releases does come at a small price, due to the need to have the control plane upgraded to the intermediate
Y-stream before getting to the next even release. Here is a quick walk through of the process the cluster will go
through during the EUS to EUS upgrade:</p>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/Before-upgrade-ctrl-plane.jpg" alt="Before upgrade ctrl plane">
</div>
<div class="title">Figure 7. Control Plane before upgrade starts</div>
</div>
<div class="paragraph">
<p>This example shows a rack of servers in a cluster on the left with a blown up explanation of 6 of these
servers on the right.</p>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/Upgrade-ctrl-plane-Yp1.jpg" alt="Upgrade ctrl plane Yp1">
</div>
<div class="title">Figure 8. Control Plane after first step of the upgrade</div>
</div>
<div class="paragraph">
<p>In this figure it shows the first step of the upgrade process where the control plane is upgraded to Y+1
along with all of the operator PODs in the cluster (even on those running on worker nodes). The last part of this step
is to reboot the control plane nodes.</p>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/Upgrade-ctrl-plane-new-EUS.jpg" alt="Upgrade ctrl plane new EUS">
</div>
<div class="title">Figure 9. Control Plane after upgrade to the next EUS release</div>
</div>
<div class="paragraph">
<p>The second step in this upgrade is to upgrade to Y+2. Just the same as the previous step, incrementing the
cluster operators, then the application operators and last of all rebooting and updating RCHOS on the control plane
nodes.</p>
</div>
<div class="paragraph">
<p>At this point in the upgrade the cluster will have the cluster control plane and all operators running on the newer EUS
release or Y+2. The worker nodes will still be on the older EUS release. Since OCP and K8s control planes are backward
compatible up to Y-2, there should be no problems in communications or control of PODs running on the worker nodes.</p>
</div>
<div class="paragraph">
<p>The last part of the upgrade is to reboot and update all of the worker nodes within the cluster. Here is an example of
how this could occur within one specific MCP of worker nodes. We will set the maxUnavailable to 20% and allow 2 out of
the 10 worker nodes reboot and upgrade at a time.</p>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/upgrade-beginning-worker-mcp.jpg" alt="upgrade beginning worker mcp">
</div>
<div class="title">Figure 10. Showing list of worker nodes in MCP1 before upgrading them</div>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/upgrade-worker-mcp-0-1.jpg" alt="upgrade worker mcp 0 1">
</div>
<div class="title">Figure 11. Upgrade Worker-0 &amp; Worker-1</div>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/upgrade-worker-mcp-2-3.jpg" alt="upgrade worker mcp 2 3">
</div>
<div class="title">Figure 12. Upgrade Worker-2 &amp; Worker-3</div>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/upgrade-worker-mcp-4-5.jpg" alt="upgrade worker mcp 4 5">
</div>
<div class="title">Figure 13. Upgrade Worker-4 &amp; Worker-5</div>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/upgrade-worker-mcp-6-7.jpg" alt="upgrade worker mcp 6 7">
</div>
<div class="title">Figure 14. Upgrade Worker-6 &amp; Worker-7</div>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/upgrade-worker-mcp-8-9.jpg" alt="upgrade worker mcp 8 9">
</div>
<div class="title">Figure 15. Upgrade Worker-8 &amp; Worker-9</div>
</div>
<div class="imageblock unresolved">
<div class="content">
<img src="images/upgrade-worker-mcp-complete.jpg" alt="upgrade worker mcp complete">
</div>
<div class="title">Figure 16. Complete upgrade of MCP2</div>
</div>
<div class="paragraph">
<p>Each MCP does not have to be independently updated, that part is completely up to the operations team and may also
relate to several factors in the CNF(s) that are running on the cluster.</p>
</div>
<div class="paragraph">
<p>Once all of the worker node MCPs have been updated you will then have a fully upgraded cluster.</p>
</div>
</div>
</div>
</div>
</div>
</article>
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
  </div>
</main>
</div>
<footer class="footer">
  <a class="rhd-logo" href="https://redhat.com" target="_blank"></div>
</footer>
<script src="../_/js/vendor/clipboard.js"></script>
<script src="../_/js/site.js"></script>
<script async src="../_/js/vendor/highlight.js"></script>
  </body>
</html>
